{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnrNFTLIS4Ov88Uwdxdwzu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amylynnn/Revision-Notebook/blob/main/Week8_web_scraping_notebook_ipynb_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRpJ6ZmM6_9D",
        "outputId": "fbf2fbbc-d340-4b8b-f8d7-13e8b5aa969b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1 - http://books.toscrape.com/\n",
            "Found 20 books on page 1\n",
            "Scraping page 2 - http://books.toscrape.com/catalogue/page-2.html\n",
            "Found 20 books on page 2\n",
            "Scraping page 3 - http://books.toscrape.com/catalogue/page-3.html\n",
            "Found 20 books on page 3\n",
            "                                   Title  Price  Rating\n",
            "0                   A Light in the Attic  51.77       3\n",
            "1                     Tipping the Velvet  53.74       1\n",
            "2                             Soumission  50.10       1\n",
            "3                          Sharp Objects  47.82       4\n",
            "4  Sapiens: A Brief History of Humankind  54.23       5\n",
            "Data saved to 'scraped_books.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import re\n",
        "\n",
        "# Define headers to identify yourself politely\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Educational purpose scraper)',\n",
        "    'Accept': 'text/html,application/xhtml+xml'\n",
        "}\n",
        "\n",
        "# Lists to store all scraped data\n",
        "all_titles = []\n",
        "all_prices = []\n",
        "all_ratings = []\n",
        "\n",
        "# Rating mapping to convert words to numbers\n",
        "rating_mapping = {\n",
        "    'One': 1,\n",
        "    'Two': 2,\n",
        "    'Three': 3,\n",
        "    'Four': 4,\n",
        "    'Five': 5\n",
        "}\n",
        "\n",
        "# Loop through pages 1 to 3\n",
        "for page_num in range(1, 4):\n",
        "    # Construct URL for each page\n",
        "    if page_num == 1:\n",
        "        url = 'http://books.toscrape.com/'\n",
        "    else:\n",
        "        url = f'http://books.toscrape.com/catalogue/page-{page_num}.html'\n",
        "\n",
        "    print(f\"Scraping page {page_num} - {url}\")\n",
        "\n",
        "    # Request the page\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to scrape page {page_num}\")\n",
        "        continue\n",
        "\n",
        "    # Parse with BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all book containers\n",
        "    book_containers = soup.find_all('article', class_='product_pod')\n",
        "    print(f\"Found {len(book_containers)} books on page {page_num}\")\n",
        "\n",
        "    # Extract data from each book\n",
        "    for book in book_containers:\n",
        "        # Title\n",
        "        title = book.h3.a['title']\n",
        "        all_titles.append(title)\n",
        "\n",
        "        # Price (raw string)\n",
        "        price = book.find('p', class_='price_color').text\n",
        "        all_prices.append(price)\n",
        "\n",
        "        # Rating (class name)\n",
        "        star_rating = book.find('p', class_='star-rating')['class'][1]\n",
        "        all_ratings.append(star_rating)\n",
        "\n",
        "    # Be polite and wait a second before next request\n",
        "    time.sleep(1)\n",
        "\n",
        "# Create DataFrame\n",
        "books_df = pd.DataFrame({\n",
        "    'Title': all_titles,\n",
        "    'Price': all_prices,\n",
        "    'Rating': all_ratings\n",
        "})\n",
        "\n",
        "# Clean 'Price' column - remove 'Â', '£', whitespace and convert to float\n",
        "books_df['Price'] = (\n",
        "    books_df['Price']\n",
        "    .str.replace('Â', '', regex=False)\n",
        "    .str.replace('£', '', regex=False)\n",
        "    .str.strip()\n",
        "    .astype(float)\n",
        ")\n",
        "\n",
        "# Convert rating words to numbers\n",
        "books_df['Rating'] = books_df['Rating'].map(rating_mapping)\n",
        "\n",
        "# Show cleaned DataFrame head\n",
        "print(books_df.head())\n",
        "\n",
        "# Save to CSV\n",
        "books_df.to_csv('scraped_books.csv', index=False)\n",
        "print(\"Data saved to 'scraped_books.csv'\")\n"
      ]
    }
  ]
}